{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Train using Azure Machine Learning Compute\n",
    "\n",
    "* Initialize a Workspace\n",
    "* Create an Experiment\n",
    "* Introduction to AmlCompute\n",
    "* Submit an AmlCompute run in a few different ways\n",
    "    - Provision as a run based compute target \n",
    "    - Provision as a persistent compute target (Basic)\n",
    "    - Provision as a persistent compute target (Advanced)\n",
    "* Additional operations to perform on AmlCompute\n",
    "* Find the best model in the run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "If you are using an Azure Machine Learning Notebook VM, you are all set.  Otherwise, go through the [configuration](../../../configuration.ipynb) Notebook first if you haven't already to establish your connection to the AzureML Workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.85\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a Workspace\n",
    "\n",
    "Initialize a workspace object from persisted configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "create workspace"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiml50dg2ai\n",
      "mlops-demo-rg\n",
      "westeurope\n",
      "6be80d16-1b1d-465b-bbdd-a298a0cbbf89\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create An Experiment\n",
    "\n",
    "**Experiment** is a logical container in an Azure ML Workspace. It hosts run records which can include run metrics and output artifacts from your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'train-on-amlcompute'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to AmlCompute\n",
    "\n",
    "Azure Machine Learning Compute is managed compute infrastructure that allows the user to easily create single to multi-node compute of the appropriate VM Family. It is created **within your workspace region** and is a resource that can be used by other users in your workspace. It autoscales by default to the max_nodes, when a job is submitted, and executes in a containerized environment packaging the dependencies as specified by the user. \n",
    "\n",
    "Since it is managed compute, job scheduling and cluster management are handled internally by Azure Machine Learning service. \n",
    "\n",
    "For more information on Azure Machine Learning Compute, please read [this article](https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute)\n",
    "\n",
    "If you are an existing BatchAI customer who is migrating to Azure Machine Learning, please read [this article](https://aka.ms/batchai-retirement)\n",
    "\n",
    "**Note**: As with other Azure services, there are limits on certain resources (for eg. AmlCompute quota) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota.\n",
    "\n",
    "\n",
    "The training script `train.py` is already created for you. Let's have a look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run customer container training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./workspace/train.py'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "project_folder = './workspace'\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "shutil.copy('train.py', project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73b28dbf5704b5c8fd80a65302eb109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/train-on-amlcompute/runs/train-on-amlcompute_1588435424_b5dd9c87?wsid=/subscriptions/6be80d16-1b1d-465b-bbdd-a298a0cbbf89/resourcegroups/mlops-demo-rg/workspaces/aiml50dg2ai\", \"run_id\": \"train-on-amlcompute_1588435424_b5dd9c87\", \"run_properties\": {\"run_id\": \"train-on-amlcompute_1588435424_b5dd9c87\", \"created_utc\": \"2020-05-02T16:03:49.536806Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"b60b84a0-693b-49ba-81c5-d86bb62bc317\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_40c3ef11c680b867cd5d0aea7a98ca85a51a101bf202b0d05b84f957938c1320_d.txt\": \"https://aiml50dg2aistorage.blob.core.windows.net/azureml/ExperimentRun/dcid.train-on-amlcompute_1588435424_b5dd9c87/azureml-logs/55_azureml-execution-tvmps_40c3ef11c680b867cd5d0aea7a98ca85a51a101bf202b0d05b84f957938c1320_d.txt?sv=2019-02-02&sr=b&sig=iROx7N2ybCVUI1rczKfZLCjKD%2F4Ta2GlFmOu8U%2BYZog%3D&st=2020-05-02T16%3A15%3A26Z&se=2020-05-03T00%3A25%3A26Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/55_azureml-execution-tvmps_40c3ef11c680b867cd5d0aea7a98ca85a51a101bf202b0d05b84f957938c1320_d.txt\"]], \"run_duration\": \"0:21:36\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"2020-05-02T16:23:08Z Starting output-watcher...\\n2020-05-02T16:23:08Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\\nUsing default tag: latest\\nlatest: Pulling from continuumio/anaconda3\\n68ced04f60ab: Pulling fs layer\\n57047f2400d7: Pulling fs layer\\n8b26dd278326: Pulling fs layer\\n68ced04f60ab: Verifying Checksum\\n68ced04f60ab: Download complete\\n57047f2400d7: Verifying Checksum\\n57047f2400d7: Download complete\\n8b26dd278326: Verifying Checksum\\n8b26dd278326: Download complete\\n68ced04f60ab: Pull complete\\n57047f2400d7: Pull complete\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.85\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use a custom Docker image\n",
    "from azureml.core.container_registry import ContainerRegistry\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# this is an image available in Docker Hub\n",
    "image_name = 'continuumio/anaconda3'\n",
    "\n",
    "# you can also point to an image in a private ACR\n",
    "image_registry_details = ContainerRegistry()\n",
    "image_registry_details.address = \"myregistry.azurecr.io\"\n",
    "image_registry_details.username = \"username\"\n",
    "image_registry_details.password = \"password\"\n",
    "\n",
    "# Find the compute\n",
    "cpu_cluster_name = \"cpu-cluster\"\n",
    "cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "\n",
    "est = Estimator(source_directory=project_folder, \n",
    "                # We can also pass params:\n",
    "                # script_params={\n",
    "                #     '--numbers-in-sequence': 10\n",
    "                # }, \n",
    "                compute_target= cpu_cluster.name, # We can run even local if docker is present 'local', \n",
    "                entry_script='train.py',\n",
    "                # If I have already all my dependencies baked in the image like in our case\n",
    "                # don't let the system build a new conda environment\n",
    "                user_managed=True,\n",
    "                # Other wise we can define conda dependencies to install which will \n",
    "                # build a custom image on top of the one we specified. E.g. if we\n",
    "                # select miniconda3 which doesn't have any data science packages prebaked\n",
    "                # you needed to uncomment the following:\n",
    "                # user_managed=False, # Optional since this is the default value\n",
    "                # conda_packages=['scikit-learn'],\n",
    "                custom_docker_image=image_name,\n",
    "                # uncomment below line to use your private ACR\n",
    "                # image_registry_details=image_registry_details,\n",
    "                # The following is needed if using default training images \n",
    "                # se_gpu = true,\n",
    "                )\n",
    "\n",
    "est.run_config.save(\"./SampleCustomImage.runconfig\")\n",
    "\n",
    "run = experiment.submit(est)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "# Default datastore, the Azure Blob Store associated with your workspace.\n",
    "def_blob_store = ws.get_default_datastore() \n",
    "# The following call GETS the Azure Blob Store associated with your workspace.\n",
    "# Note that workspaceblobstore is **the name of this store and CANNOT BE CHANGED and must be used as is** \n",
    "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "print(\"Blobstore's name: {}\".format(def_blob_store.name))\n",
    "\n",
    "\n",
    "# Upload a file there\n",
    "def_blob_store.upload_files([\"./SampleCustomImage.runconfig\"], target_path=\"SampleUpload\", overwrite=True)\n",
    "print(\"Upload call completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure.storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: dsadsadasdsadsads\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.common.cloudstorageaccount import CloudStorageAccount\n",
    "from azure.storage.common.models import AccessPolicy\n",
    "from azure.storage.blob import BlockBlobService, PageBlobService, AppendBlobService\n",
    "from azure.storage.models import CorsRule, Logging, Metrics, RetentionPolicy, ResourceTypes, AccountPermissions\n",
    "from azure.storage.blob.models import BlobBlock, ContainerPermissions, ContentSettings\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "import json\n",
    "settings= {}\n",
    "with open('./settings.json') as f:\n",
    "    settings = json.load(f)\n",
    "\n",
    "\n",
    "account_name = settings[\"STORAGE_ACCOUNT_NAME\"]\n",
    "account_key = settings[\"STORAGE_ACCOUNT_KEY\"]\n",
    "\n",
    "account = CloudStorageAccount(account_name, account_key)\n",
    "\n",
    "blobService = account.create_block_blob_service()\n",
    "\n",
    "container_name = \"testattach\"\n",
    "\n",
    "policyId = \"2020-04-29-readlist-access\"\n",
    "\n",
    "# Set access policy on container\n",
    "access_policy = AccessPolicy(permission=ContainerPermissions(read=True, list=True),\n",
    "                                     expiry=datetime.utcnow() + timedelta(hours=10))\n",
    "identifiers = {policyId: access_policy}\n",
    "acl = blobService.set_container_acl(container_name, identifiers)\n",
    "\n",
    "# Wait 30 seconds for acl to propagate\n",
    "time.sleep(30)\n",
    "\n",
    "\n",
    "# Indicates to use the access policy set on the container\n",
    "token = blobService.generate_container_shared_access_signature(\n",
    "            container_name,\n",
    "            id=policyId\n",
    ")\n",
    "\n",
    "print(\"Token: {}\".format(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.datastore import Datastore\n",
    "\n",
    "datastore_name=\"test_datastore\"\n",
    "\n",
    "\n",
    "iris_data = Datastore.register_azure_blob_container(ws, \n",
    "                      datastore_name=datastore_name, \n",
    "                      container_name= container_name, \n",
    "                      account_name=account_name, \n",
    "                      sas_token=token,                              \n",
    "                      overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmp6lv1fnze\n",
      "['Install.txt']\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "import os\n",
    "\n",
    "# The following call GETS the Azure Blob Store associated with your workspace.\n",
    "# Note that workspaceblobstore is **the name of this store and CANNOT BE CHANGED and must be used as is** \n",
    "datastore = Datastore(ws, \"test_datastore\")\n",
    "\n",
    "datastore_path = [\n",
    "  DataPath(datastore, '*.txt')\n",
    "]\n",
    "\n",
    "dataset = Dataset.File.from_files(path=datastore_path)\n",
    "dataset_name = 'txt_dataset'\n",
    "\n",
    "# Register the dataset\n",
    "dataset.register(workspace=ws,\n",
    "                 name=dataset_name,\n",
    "                 description='Text files in test_datastore',\n",
    "                 create_new_version=True)\n",
    "\n",
    "# Optionally you can create a temp mounting path\n",
    "# import tempfile\n",
    "# mounted_path = tempfile.mkdtemp()\n",
    "# print (mounted_path)\n",
    "# And you can mount in specific location\n",
    "# with dataset.mount(mounted_path) as mount_context:\n",
    "\n",
    "with dataset.mount() as mount_context:\n",
    "    mount_context.start()\n",
    "    # This is the point where the sataset is mounted\n",
    "    print(mount_context.mount_point)\n",
    "    # list top level mounted files and folders in the dataset\n",
    "    print(os.listdir(mount_context.mount_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d94b64051424501b4c722c7ecd759d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/train-on-amlcompute/runs/train-on-amlcompute_1588436338_1111b717?wsid=/subscriptions/6be80d16-1b1d-465b-bbdd-a298a0cbbf89/resourcegroups/mlops-demo-rg/workspaces/aiml50dg2ai\", \"run_id\": \"train-on-amlcompute_1588436338_1111b717\", \"run_properties\": {\"run_id\": \"train-on-amlcompute_1588436338_1111b717\", \"created_utc\": \"2020-05-02T16:18:59.768126Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"b60b84a0-693b-49ba-81c5-d86bb62bc317\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_f1eeac190a54e6b91aca37a0c81d1db1fc8223e045b6cd12e76a889b41d933b8_d.txt\": \"https://aiml50dg2aistorage.blob.core.windows.net/azureml/ExperimentRun/dcid.train-on-amlcompute_1588436338_1111b717/azureml-logs/55_azureml-execution-tvmps_f1eeac190a54e6b91aca37a0c81d1db1fc8223e045b6cd12e76a889b41d933b8_d.txt?sv=2019-02-02&sr=b&sig=Hggttcm1pfIeQPaTzX%2BC18gWlwQbqzTpjW9WJn2V5nc%3D&st=2020-05-02T16%3A15%3A27Z&se=2020-05-03T00%3A25%3A27Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/55_azureml-execution-tvmps_f1eeac190a54e6b91aca37a0c81d1db1fc8223e045b6cd12e76a889b41d933b8_d.txt\"]], \"run_duration\": \"0:06:27\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"2020-05-02T16:23:07Z Starting output-watcher...\\n2020-05-02T16:23:07Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\\nUsing default tag: latest\\nlatest: Pulling from continuumio/anaconda3\\n68ced04f60ab: Pulling fs layer\\n57047f2400d7: Pulling fs layer\\n8b26dd278326: Pulling fs layer\\n68ced04f60ab: Verifying Checksum\\n68ced04f60ab: Download complete\\n57047f2400d7: Verifying Checksum\\n57047f2400d7: Download complete\\n8b26dd278326: Verifying Checksum\\n8b26dd278326: Download complete\\n68ced04f60ab: Pull complete\\n57047f2400d7: Pull complete\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.85\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's attach the dataset to the estimator\n",
    "# First let's show how to get the dataset by name\n",
    "dataset = Dataset.get_by_name(workspace=ws, name=dataset_name)\n",
    "\n",
    "script_params = {\n",
    "    # mount the dataset on the remote compute and pass the mounted path as an argument to the training script\n",
    "    # the as_named_input also exposes the mount point as the DATA_FOLDER environment variable\n",
    "    # It will also be accessible via run.input_datasets['DATA_FOLDER'] if you reference the azureML SDK\n",
    "    # https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.abstract_dataset.abstractdataset?view=azure-ml-py#as-named-input-name-\n",
    "    '--data-folder': dataset.as_named_input('DATA_FOLDER').as_mount()\n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=project_folder, \n",
    "                # Pass the param to make the script ls the dir\n",
    "                script_params = script_params, \n",
    "                compute_target= cpu_cluster.name, # We can run even local if docker is present 'local', \n",
    "                entry_script='train.py',\n",
    "                user_managed=True,\n",
    "                custom_docker_image=image_name,\n",
    "                )\n",
    "\n",
    "# est.run_config.save(\"./WithMount_CustomImage.runconfig\")\n",
    "\n",
    "run = experiment.submit(est)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLOB CONTAINER LEASE STATUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  RESET LEASE STATUS OF A CONTAINER ###########\n",
    "from azure.storage.common.cloudstorageaccount import CloudStorageAccount\n",
    "\n",
    "# Retrieve the storage account and the storage key\n",
    "import json\n",
    "settings= {}\n",
    "with open('./settings.json') as f:\n",
    "    settings = json.load(f)\n",
    "account_name = settings[\"STORAGE_ACCOUNT_NAME\"]\n",
    "account_key = settings[\"STORAGE_ACCOUNT_KEY\"]\n",
    "\n",
    "# The container that has Lease status broken\n",
    "container_name='test-lease'\n",
    "\n",
    "# Create a blobservice client from a storage account client\n",
    "account = CloudStorageAccount(account_name, account_key)\n",
    "blobService = account.create_block_blob_service()\n",
    "    \n",
    "# Get a container lease\n",
    "lease_id=blobService.acquire_container_lease(container_name, lease_duration=-1)\n",
    "# Release that lease\n",
    "blobService.release_container_lease(container_name,lease_id)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "rndazurescript"
   }
  ],
  "categories": [
   "how-to-use-azureml",
   "training"
  ],
  "category": "training",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "Diabetes"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "None"
  ],
  "friendly_name": "Train on Azure Machine Learning Compute",
  "index_order": 1,
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "tags": [
   "None"
  ],
  "task": "Submit a run on Azure Machine Learning Compute."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
